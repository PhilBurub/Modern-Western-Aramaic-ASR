{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZskFj_bltO-"
      },
      "source": [
        "!/usr/bin/env python\n",
        "coding=utf-8\n",
        "Copyright 2021 The HuggingFace Inc. team. All rights reserved.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbEi8BSjltPD"
      },
      "source": [
        "Pre-Training a 🤗 Wav2Vec2 model on unlabeled audio data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Es1Ua5TltPE"
      },
      "outputs": [],
      "source": [
        "with open('requirements.txt', 'w', encoding='utf-8') as f:\n",
        "    f.write('''\n",
        "accelerate==0.15.0\n",
        "datasets==2.18.0\n",
        "huggingface-hub==0.22.2\n",
        "jiwer==2.5.1\n",
        "librosa==0.9.2\n",
        "espnet==202211\n",
        "espnet_model_zoo==0.1.7\n",
        "natsort==8.2.0\n",
        "numpy==1.23.5\n",
        "omegaconf==2.2.3\n",
        "pandas==1.5.2\n",
        "parallel-wavegan==0.5.5\n",
        "pyctcdecode==0.4.0\n",
        "soundfile==0.11.0\n",
        "torch==1.13.0\n",
        "torchaudio==0.13.0\n",
        "tqdm==4.64.1\n",
        "transformers==4.24.0\n",
        "wandb==0.13.4\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t97V9lA7ltPG"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cv_yCvmqltPH"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import math\n",
        "import os\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Union\n",
        "import logging\n",
        "\n",
        "import datasets\n",
        "import torch\n",
        "from accelerate import Accelerator\n",
        "from accelerate.logging import get_logger\n",
        "from datasets import DatasetDict, concatenate_datasets, load_dataset\n",
        "import huggingface_hub\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "import transformers\n",
        "from transformers import (\n",
        "    AdamW,\n",
        "    SchedulerType,\n",
        "    Wav2Vec2Config,\n",
        "    Wav2Vec2FeatureExtractor,\n",
        "    Wav2Vec2ForPreTraining,\n",
        "    get_scheduler,\n",
        "    #is_wandb_available,\n",
        "    set_seed,\n",
        ")\n",
        "from transformers.models.wav2vec2.modeling_wav2vec2 import _compute_mask_indices, _sample_negative_indices\n",
        "from transformers.utils import send_example_telemetry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yufAI6uXltPJ"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class DataCollatorForWav2Vec2Pretraining:\n",
        "    \"\"\"\n",
        "    Data collator that will dynamically pad the inputs received and prepare masked indices\n",
        "    for self-supervised pretraining.\n",
        "\n",
        "    Args:\n",
        "        model (:class:`~transformers.Wav2Vec2ForPreTraining`):\n",
        "            The Wav2Vec2 model used for pretraining. The data collator needs to have access\n",
        "            to config and ``_get_feat_extract_output_lengths`` function for correct padding.\n",
        "        feature_extractor (:class:`~transformers.Wav2Vec2FeatureExtractor`):\n",
        "            The processor used for proccessing the data.\n",
        "        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
        "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
        "            among:\n",
        "            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
        "              sequence if provided).\n",
        "            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
        "              maximum acceptable input length for the model if that argument is not provided.\n",
        "            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
        "              different lengths).\n",
        "        max_length (:obj:`int`, `optional`):\n",
        "            Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n",
        "        pad_to_multiple_of (:obj:`int`, `optional`):\n",
        "            If set will pad the sequence to a multiple of the provided value.\n",
        "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
        "            7.5 (Volta).\n",
        "        mask_time_prob (:obj:`float`, `optional`, defaults to :obj:`0.65`):\n",
        "            Percentage (between 0 and 1) of all feature vectors along the time axis which will be masked for the contrastive task.\n",
        "            Note that overlap between masked sequences may decrease the actual percentage of masked vectors.\n",
        "            The default value is taken from the original wav2vec 2.0 article (https://arxiv.org/abs/2006.11477),\n",
        "            and results in about 49 percent of each sequence being masked on average.\n",
        "        mask_time_length (:obj:`int`, `optional`, defaults to :obj:`10`):\n",
        "            Length of each vector mask span to mask along the time axis in the contrastive task. The default value\n",
        "            originates from the original wav2vec 2.0 article and corresponds to the ``M`` variable mentioned there.\n",
        "    \"\"\"\n",
        "\n",
        "    model: Wav2Vec2ForPreTraining\n",
        "    feature_extractor: Wav2Vec2FeatureExtractor\n",
        "    padding: Union[bool, str] = \"longest\"\n",
        "    pad_to_multiple_of: Optional[int] = None\n",
        "    mask_time_prob: Optional[float] = 0.65\n",
        "    mask_time_length: Optional[int] = 10\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        # reformat list to dict and set to pytorch format\n",
        "        batch = self.feature_extractor.pad(\n",
        "            features,\n",
        "            padding=self.padding,\n",
        "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        device = batch[\"input_values\"].device\n",
        "        batch_size = batch[\"input_values\"].shape[0]\n",
        "\n",
        "        mask_indices_seq_length = self.model._get_feat_extract_output_lengths(batch[\"input_values\"].shape[-1])\n",
        "        # make sure masked sequence length is a Python scalar\n",
        "        mask_indices_seq_length = int(mask_indices_seq_length)\n",
        "\n",
        "        # make sure that no loss is computed on padded inputs\n",
        "        if batch.get(\"attention_mask\") is not None:\n",
        "            # compute real output lengths according to convolution formula\n",
        "            batch[\"sub_attention_mask\"] = self.model._get_feature_vector_attention_mask(\n",
        "                mask_indices_seq_length, batch[\"attention_mask\"]\n",
        "            )\n",
        "\n",
        "        features_shape = (batch_size, mask_indices_seq_length)\n",
        "\n",
        "        # sample randomly masked indices\n",
        "        mask_time_indices = _compute_mask_indices(\n",
        "            features_shape,\n",
        "            self.mask_time_prob,\n",
        "            self.mask_time_length,\n",
        "            attention_mask=batch.get(\"sub_attention_mask\"),\n",
        "        )\n",
        "\n",
        "        # sample negative indices\n",
        "        sampled_negative_indices = _sample_negative_indices(\n",
        "            features_shape,\n",
        "            self.model.config.num_negatives,\n",
        "            mask_time_indices=mask_time_indices,\n",
        "        )\n",
        "        batch[\"mask_time_indices\"] = torch.tensor(mask_time_indices, dtype=torch.long, device=device)\n",
        "        batch[\"sampled_negative_indices\"] = torch.tensor(sampled_negative_indices, dtype=torch.long, device=device)\n",
        "\n",
        "        return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zT_6pqI6ltPL"
      },
      "outputs": [],
      "source": [
        "def multiply_grads(params, c):\n",
        "    \"\"\"Multiplies grads by a constant *c*.\"\"\"\n",
        "    for p in params:\n",
        "        if p.grad is not None:\n",
        "            if torch.is_tensor(c):\n",
        "                c = c.to(p.grad.device)\n",
        "            p.grad.data.mul_(c)\n",
        "\n",
        "\n",
        "def get_grad_norm(params, scale=1):\n",
        "    \"\"\"Compute grad norm given a gradient scale.\"\"\"\n",
        "    total_norm = 0.0\n",
        "    for p in params:\n",
        "        if p.grad is not None:\n",
        "            param_norm = (p.grad.detach().data / scale).norm(2)\n",
        "            total_norm += param_norm.item() ** 2\n",
        "    total_norm = total_norm**0.5\n",
        "    return total_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29baUICdltPM"
      },
      "outputs": [],
      "source": [
        "logger = get_logger(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22gf1BshltPN"
      },
      "outputs": [],
      "source": [
        "def reshape2dict(text):\n",
        "    parts = text.lstrip('--').split('=')\n",
        "    return parts[0] + ': ' + parts[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d76-c1Ugw7WE",
        "outputId": "e61d5322-11d0-474e-c09e-4da4708d77b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhyNZJNYltPN"
      },
      "outputs": [],
      "source": [
        "class MagicClass:\n",
        "    def __init__(self):\n",
        "        self.args = {\n",
        "                    'dataset_name': \"/content/drive/MyDrive/copt\",\n",
        "                    'dataset_config_names': ['default'],\n",
        "                    'dataset_split_names': ['train'],\n",
        "                    'model_name_or_path': 'facebook/wav2vec2-xls-r-300m',\n",
        "                    'feature_extractor_config': '/content/drive/MyDrive/checkpoints_9/checkpoint-10000/config.json',\n",
        "                    'output_dir': '/content/drive/MyDrive/checkpoints_10',\n",
        "                    'max_train_steps': 50000,\n",
        "                    'num_warmup_steps': 25000,\n",
        "                    'gradient_accumulation_steps': 1,\n",
        "                    'learning_rate': 25e-6,\n",
        "                    'weight_decay': 0.01,\n",
        "                    'max_duration_in_seconds': 30.0,\n",
        "                    'min_duration_in_seconds': 1.0,\n",
        "                    'logging_steps': 100,\n",
        "                    'saving_steps': 1000,\n",
        "                    'per_device_train_batch_size': 2,\n",
        "                    'per_device_eval_batch_size': 2,\n",
        "                    'adam_beta1': 0.9,\n",
        "                    'adam_beta2': 0.98,\n",
        "                    'adam_epsilon': 1e-06,\n",
        "                    'gradient_checkpointing': True,\n",
        "                    'wandb_project_name': 'copt-thesis',\n",
        "                    'wandb_run_name': 'run_10',\n",
        "                    'validation_split_percentage': 10,\n",
        "                    'audio_column_name': 'audio',\n",
        "                    'lr_scheduler_type': 'linear',\n",
        "                    'max_gumbel_temperature': 2.0,\n",
        "                    'min_gumbel_temperature': 0.5,\n",
        "                    'gumbel_temperature_decay': 0.999995,\n",
        "                    'seed': 0,\n",
        "                    'mask_time_prob': 0.5,\n",
        "                    'save_total_limit': 3\n",
        "                    }\n",
        "\n",
        "    def __getattr__(self, name):\n",
        "        return(self.args.get(name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_Qm-FmQltPO"
      },
      "outputs": [],
      "source": [
        "args = MagicClass()\n",
        "is_wandb_available = lambda: True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "hABxc9dd0CbD",
        "outputId": "135de836-fa39-4815-e55e-52accc460e6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "wandb version 0.16.6 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240427_072638-il5im1yl</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/pburub/copt-thesis/runs/il5im1yl\" target=\"_blank\">run_10</a></strong> to <a href=\"https://wandb.ai/pburub/copt-thesis\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# See all possible arguments in src/transformers/args.py\n",
        "# or by passing the --help flag to this script.\n",
        "# We now keep distinct sets of args, for a cleaner separation of concerns.\n",
        "# Initialize the accelerator. We will let the accelerator handle device placement for us in this example.\n",
        "accelerator = Accelerator()\n",
        "logger.info(accelerator.state)\n",
        "\n",
        "# Setup logging, we only want one process per machine to log things on the screen.\n",
        "# accelerator.is_local_main_process is only True for one process per machine.\n",
        "logger.setLevel(logging.INFO if accelerator.is_local_main_process else logging.ERROR)\n",
        "if accelerator.is_local_main_process:\n",
        "    datasets.utils.logging.set_verbosity_warning()\n",
        "    transformers.utils.logging.set_verbosity_info()\n",
        "\n",
        "    # set up weights and biases if available\n",
        "    if is_wandb_available():\n",
        "        import wandb\n",
        "\n",
        "        wandb.init(project=args.wandb_project_name, name=args.wandb_run_name)\n",
        "else:\n",
        "    datasets.utils.logging.set_verbosity_error()\n",
        "    transformers.utils.logging.set_verbosity_error()\n",
        "\n",
        "# If passed along, set the training seed now.\n",
        "if args.seed is not None:\n",
        "    set_seed(args.seed)\n",
        "\n",
        "# Handle the repository creation\n",
        "if accelerator.is_main_process:\n",
        "    if args.push_to_hub and not args.preprocessing_only:\n",
        "        if args.hub_model_id is None:\n",
        "            repo_name = get_full_repo_name(Path(args.output_dir).name, token=args.hub_token)\n",
        "        else:\n",
        "            repo_name = args.hub_model_id\n",
        "        repo = Repository(args.output_dir, clone_from=repo_name)\n",
        "    elif args.output_dir is not None:\n",
        "        os.makedirs(args.output_dir, exist_ok=True)\n",
        "accelerator.wait_for_everyone()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "bf7f58151ac647cc80cda03a63f2b81b",
            "a82245e48ec9409fa16a5592dfec94b7",
            "1c033c9c66234856aaebb798ea6068fb",
            "ce751320f3a44e898144fa6748dd9da8",
            "eb53e80df29746ef9d5aef75b7f21f37",
            "cdb2eab7c1f14825a56a27947bcda78f",
            "3207a938bbff4176be594c91a894e66b",
            "d08c2ecf5ffa4ab08515d673d5703e4a",
            "0a5e7bdd82a547deb5bfff3b67898e8a",
            "b4de83ae4782433395f708825f6d4554",
            "66657332642e4b2b840e2f11ebefb4ce",
            "8e250fd1cf494807ab5472b9d5d31537",
            "e8ec8c75b5c0492e9ccf25255affcbca",
            "e8a1dd58d3f04c6f8f73f259ffa3eaaa",
            "ec5cf077253f4ce38db5f4859ec4ded0",
            "48a1f60d2aa14ce2890b87afa1ed9382",
            "87f0ba8d91714d2fbc57089a82cf4e12",
            "2d278f7b50dd4ef9ba8ea28a5df99eae",
            "6cda0e8a22014ec6ac8eb32ad2e3f1ae",
            "0ddc76efd5e84c65940f14d1d6e56c5f",
            "de815217b00e4fcc86c55b8c28d19ab4",
            "1ea777a415f0424c810f7b06ba1f4e93"
          ]
        },
        "id": "RCVRnobq0Fly",
        "outputId": "1dd4d97d-c674-4157-cdd0-0d5a1f590cfe"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/3099 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf7f58151ac647cc80cda03a63f2b81b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e250fd1cf494807ab5472b9d5d31537"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 1. Download and create train, validation dataset\n",
        "# We load all dataset configuration and datset split pairs passed in\n",
        "# ``args.dataset_config_names`` and ``args.dataset_split_names``\n",
        "datasets_splits = []\n",
        "for dataset_config_name, train_split_name in zip(args.dataset_config_names, args.dataset_split_names):\n",
        "    # load dataset\n",
        "    dataset_split = load_dataset(\n",
        "        args.dataset_name, dataset_config_name, split=train_split_name, cache_dir=args.cache_dir\n",
        "    )\n",
        "    datasets_splits.append(dataset_split)\n",
        "\n",
        "# Next, we concatenate all configurations and splits into a single training dataset\n",
        "raw_datasets = DatasetDict()\n",
        "if len(datasets_splits) > 1:\n",
        "    raw_datasets[\"train\"] = concatenate_datasets(datasets_splits).shuffle(seed=args.seed)\n",
        "else:\n",
        "    raw_datasets[\"train\"] = datasets_splits[0]\n",
        "\n",
        "# Take ``args.validation_split_percentage`` from the training dataset for the validation_split_percentage\n",
        "num_validation_samples = raw_datasets[\"train\"].num_rows * args.validation_split_percentage // 100\n",
        "\n",
        "if num_validation_samples == 0:\n",
        "    raise ValueError(\n",
        "        \"`args.validation_split_percentage` is less than a single sample \"\n",
        "        f\"for {len(raw_datasets['train'])} training samples. Increase \"\n",
        "        \"`args.num_validation_split_percentage`. \"\n",
        "    )\n",
        "\n",
        "raw_datasets[\"validation\"] = raw_datasets[\"train\"].select(range(num_validation_samples))\n",
        "raw_datasets[\"train\"] = raw_datasets[\"train\"].select(range(num_validation_samples, raw_datasets[\"train\"].num_rows))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSLr7yfE0Tvj"
      },
      "outputs": [],
      "source": [
        "# 2. Now we preprocess the datasets including loading the audio, resampling and normalization\n",
        "# Thankfully, `datasets` takes care of automatically loading and resampling the audio,\n",
        "# so that we just need to set the correct target sampling rate and normalize the input\n",
        "# via the `feature_extractor`\n",
        "if args.feature_extractor_config is not None:\n",
        "    feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(args.model_name_or_path, config=args.feature_extractor_config)\n",
        "else:\n",
        "    feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(args.model_name_or_path)\n",
        "\n",
        "# make sure that dataset decodes audio with correct sampling rate\n",
        "raw_datasets = raw_datasets.cast_column(\n",
        "    args.audio_column_name, datasets.features.Audio(sampling_rate=feature_extractor.sampling_rate)\n",
        ")\n",
        "\n",
        "# only normalized-inputs-training is supported\n",
        "if not feature_extractor.do_normalize:\n",
        "    raise ValueError(\n",
        "        \"Training is only supported for normalized inputs. \" \"Make sure ``feature_extractor.do_normalize == True``\"\n",
        "    )\n",
        "\n",
        "# set max & min audio length in number of samples\n",
        "max_length = int(args.max_duration_in_seconds * feature_extractor.sampling_rate)\n",
        "min_length = int(args.min_duration_in_seconds * feature_extractor.sampling_rate)\n",
        "\n",
        "def prepare_dataset(batch):\n",
        "    sample = batch[args.audio_column_name]\n",
        "\n",
        "    inputs = feature_extractor(\n",
        "        sample[\"array\"], sampling_rate=sample[\"sampling_rate\"], max_length=max_length, truncation=True\n",
        "    )\n",
        "    batch[\"input_values\"] = inputs.input_values[0]\n",
        "    batch[\"input_length\"] = len(inputs.input_values[0])\n",
        "\n",
        "    return batch\n",
        "\n",
        "# load via mapped files via path\n",
        "cache_file_names = None\n",
        "if args.train_cache_file_name is not None:\n",
        "    cache_file_names = {\"train\": args.train_cache_file_name, \"validation\": args.validation_cache_file_name}\n",
        "\n",
        "# load audio files into numpy arrays\n",
        "with accelerator.main_process_first():\n",
        "    vectorized_datasets = raw_datasets.map(\n",
        "        prepare_dataset,\n",
        "        num_proc=args.preprocessing_num_workers,\n",
        "        remove_columns=raw_datasets[\"train\"].column_names,\n",
        "        cache_file_names=cache_file_names,\n",
        "    )\n",
        "\n",
        "    if min_length > 0.0:\n",
        "        vectorized_datasets = vectorized_datasets.filter(\n",
        "            lambda x: x > min_length,\n",
        "            num_proc=args.preprocessing_num_workers,\n",
        "            input_columns=[\"input_length\"],\n",
        "        )\n",
        "\n",
        "    vectorized_datasets = vectorized_datasets.remove_columns(\"input_length\")\n",
        "\n",
        "# for large datasets it is advised to run the preprocessing on a\n",
        "# single machine first with ``args.preprocessing_only`` since there will mostly likely\n",
        "# be a timeout when running the script in distributed mode.\n",
        "# In a second step ``args.preprocessing_only`` can then be set to `False` to load the\n",
        "# cached dataset\n",
        "if args.preprocessing_only:\n",
        "    raise AssertionError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caPjkUOkCX4K"
      },
      "outputs": [],
      "source": [
        "# 3. Load model\n",
        "if args.feature_extractor_config is not None:\n",
        "    config = Wav2Vec2Config.from_pretrained(args.feature_extractor_config)\n",
        "else:\n",
        "    config = Wav2Vec2Config.from_pretrained(args.model_name_or_path)\n",
        "# pretraining is only supported for \"newer\" stable layer norm architecture\n",
        "# apply_spec_augment has to be True, mask_feature_prob has to be 0.0\n",
        "\n",
        "if not config.do_stable_layer_norm or config.feat_extract_norm != \"layer\":\n",
        "    raise ValueError(\n",
        "        \"PreTraining is only supported for ``config.do_stable_layer_norm=True`` and ``config.feat_extract_norm='layer'\"\n",
        "    )\n",
        "\n",
        "# initialize model\n",
        "if args.feature_extractor_config is not None:\n",
        "    model = Wav2Vec2ForPreTraining.from_pretrained(args.model_name_or_path, config=args.feature_extractor_config)\n",
        "else:\n",
        "    model = Wav2Vec2ForPreTraining.from_pretrained(args.model_name_or_path)\n",
        "\n",
        "# Number of trainable parameters\n",
        "print(f'Total model parameters: {sum(p.numel() for p in model.parameters())}')\n",
        "print(f'Trainable model parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}')\n",
        "\n",
        "# Activate gradient checkpointing if needed\n",
        "if args.gradient_checkpointing:\n",
        "    model.gradient_checkpointing_enable()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3P-XEZfCbag"
      },
      "outputs": [],
      "source": [
        "# 4. Define data collator, optimizer and scheduler\n",
        "data_collator = DataCollatorForWav2Vec2Pretraining(\n",
        "    model=model, feature_extractor=feature_extractor, pad_to_multiple_of=args.pad_to_multiple_of\n",
        ")\n",
        "train_dataloader = DataLoader(\n",
        "    vectorized_datasets[\"train\"],\n",
        "    shuffle=True,\n",
        "    collate_fn=data_collator,\n",
        "    batch_size=args.per_device_train_batch_size,\n",
        ")\n",
        "eval_dataloader = DataLoader(\n",
        "    vectorized_datasets[\"validation\"], collate_fn=data_collator, batch_size=args.per_device_eval_batch_size\n",
        ")\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.AdamW(\n",
        "    list(model.parameters()),\n",
        "    lr=args.learning_rate,\n",
        "    betas=[args.adam_beta1, args.adam_beta2],\n",
        "    eps=args.adam_epsilon,\n",
        ")\n",
        "\n",
        "# Prepare everything with our `accelerator`.\n",
        "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
        "    model, optimizer, train_dataloader, eval_dataloader\n",
        ")\n",
        "\n",
        "# Scheduler and math around the number of training steps.\n",
        "num_update_steps_per_epoch = math.ceil(len(train_dataloader) / args.gradient_accumulation_steps)\n",
        "\n",
        "if args.max_train_steps is None:\n",
        "    args.max_train_steps = args.num_train_epochs * num_update_steps_per_epoch\n",
        "else:\n",
        "    args.num_train_epochs = math.ceil(args.max_train_steps / num_update_steps_per_epoch)\n",
        "\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=args.lr_scheduler_type,\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=args.num_warmup_steps,\n",
        "    num_training_steps=args.max_train_steps,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1f4e7cd9c57a4a058fa00f884320c299",
            "df671a6383484181b5b2bef16bc9a17d",
            "a3d6772b7a4549d1a50368484a36af27",
            "71b9d4af78d94f6db1929c583573cfb9",
            "2b64aa135fe3492a9997122d10a361f3",
            "38cacdf87e7c4294bbb4d92411f76189",
            "c2f1bfe54bf34900a2f3413eeaf55e2d",
            "2fbbe848d0cd42d2ba78890fcb6fcd95",
            "d44c205527864f3d876f3a243bdd68ce",
            "59d47e40581a488bac5af0aafce183a3",
            "ecb9f62ca56a40a88fd350909a799b54"
          ]
        },
        "id": "3IIjj1gnltPQ",
        "outputId": "9ffebd19-6195-4089-8086-b1ab31b7443a"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:***** Running training *****\n",
            "INFO:__main__:  Num examples = 2790\n",
            "INFO:__main__:  Num Epochs = 36\n",
            "INFO:__main__:  Instantaneous batch size per device = 2\n",
            "INFO:__main__:  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
            "INFO:__main__:  Gradient Accumulation steps = 1\n",
            "INFO:__main__:  Total optimization steps = 50000\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f4e7cd9c57a4a058fa00f884320c299",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/50000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| completed_steps: 1.000e+02| loss: 3.634e+00| constrast_loss: 3.546e+00| div_loss: 8.857e-01| %_mask_idx: 4.517e-01| ppl: 7.313e+01| lr: 1.000e-07| temp: 1.999e+00| grad_norm: 8.119e+00\n",
            "| completed_steps: 2.000e+02| loss: 2.929e+00| constrast_loss: 2.849e+00| div_loss: 7.986e-01| %_mask_idx: 5.044e-01| ppl: 1.289e+02| lr: 2.000e-07| temp: 1.998e+00| grad_norm: 5.096e+00\n",
            "| completed_steps: 3.000e+02| loss: 3.895e+00| constrast_loss: 3.815e+00| div_loss: 8.053e-01| %_mask_idx: 4.675e-01| ppl: 1.246e+02| lr: 3.000e-07| temp: 1.997e+00| grad_norm: 1.290e+01\n",
            "| completed_steps: 4.000e+02| loss: 3.200e+00| constrast_loss: 3.122e+00| div_loss: 7.795e-01| %_mask_idx: 4.760e-01| ppl: 1.411e+02| lr: 4.000e-07| temp: 1.996e+00| grad_norm: 4.434e+00\n",
            "| completed_steps: 5.000e+02| loss: 4.077e+00| constrast_loss: 3.995e+00| div_loss: 8.208e-01| %_mask_idx: 4.854e-01| ppl: 1.147e+02| lr: 5.000e-07| temp: 1.995e+00| grad_norm: 9.984e+00\n",
            "| completed_steps: 6.000e+02| loss: 3.284e+00| constrast_loss: 3.204e+00| div_loss: 8.031e-01| %_mask_idx: 4.740e-01| ppl: 1.260e+02| lr: 6.000e-07| temp: 1.994e+00| grad_norm: 4.445e+00\n",
            "| completed_steps: 7.000e+02| loss: 3.512e+00| constrast_loss: 3.425e+00| div_loss: 8.687e-01| %_mask_idx: 5.148e-01| ppl: 8.403e+01| lr: 7.000e-07| temp: 1.993e+00| grad_norm: 6.390e+00\n",
            "| completed_steps: 8.000e+02| loss: 5.066e+00| constrast_loss: 4.984e+00| div_loss: 8.196e-01| %_mask_idx: 5.157e-01| ppl: 1.155e+02| lr: 8.000e-07| temp: 1.992e+00| grad_norm: 2.105e+01\n",
            "| completed_steps: 9.000e+02| loss: 3.518e+00| constrast_loss: 3.436e+00| div_loss: 8.157e-01| %_mask_idx: 4.637e-01| ppl: 1.179e+02| lr: 9.000e-07| temp: 1.991e+00| grad_norm: 5.521e+00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in /content/drive/MyDrive/checkpoints_10/checkpoint-1000/config.json\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| completed_steps: 1.000e+03| loss: 3.624e+00| constrast_loss: 3.539e+00| div_loss: 8.511e-01| %_mask_idx: 5.043e-01| ppl: 9.527e+01| lr: 1.000e-06| temp: 1.990e+00| grad_norm: 5.037e+00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in /content/drive/MyDrive/checkpoints_10/checkpoint-1000/pytorch_model.bin\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| completed_steps: 1.100e+03| loss: 3.125e+00| constrast_loss: 3.044e+00| div_loss: 8.019e-01| %_mask_idx: 5.097e-01| ppl: 1.268e+02| lr: 1.100e-06| temp: 1.989e+00| grad_norm: 4.154e+00\n",
            "| completed_steps: 1.200e+03| loss: 3.639e+00| constrast_loss: 3.559e+00| div_loss: 8.018e-01| %_mask_idx: 4.874e-01| ppl: 1.268e+02| lr: 1.200e-06| temp: 1.988e+00| grad_norm: 6.821e+00\n",
            "| completed_steps: 1.300e+03| loss: 2.964e+00| constrast_loss: 2.882e+00| div_loss: 8.214e-01| %_mask_idx: 5.098e-01| ppl: 1.143e+02| lr: 1.300e-06| temp: 1.987e+00| grad_norm: 4.640e+00\n",
            "| val_loss: 2.369e+00| val_contrastive_loss: 2.286e+00| val_diversity_loss: 8.288e-01| val_num_losses: 1.000e+00\n",
            "| completed_steps: 1.400e+03| loss: 3.225e+00| constrast_loss: 3.139e+00| div_loss: 8.551e-01| %_mask_idx: 4.648e-01| ppl: 9.271e+01| lr: 1.400e-06| temp: 1.986e+00| grad_norm: 8.460e+00\n",
            "| completed_steps: 1.500e+03| loss: 2.808e+00| constrast_loss: 2.731e+00| div_loss: 7.712e-01| %_mask_idx: 4.908e-01| ppl: 1.464e+02| lr: 1.500e-06| temp: 1.985e+00| grad_norm: 3.936e+00\n",
            "| completed_steps: 1.600e+03| loss: 3.163e+00| constrast_loss: 3.080e+00| div_loss: 8.261e-01| %_mask_idx: 4.990e-01| ppl: 1.113e+02| lr: 1.600e-06| temp: 1.984e+00| grad_norm: 5.048e+00\n",
            "| completed_steps: 1.700e+03| loss: 3.023e+00| constrast_loss: 2.941e+00| div_loss: 8.281e-01| %_mask_idx: 4.826e-01| ppl: 1.100e+02| lr: 1.700e-06| temp: 1.983e+00| grad_norm: 6.068e+00\n",
            "| completed_steps: 1.800e+03| loss: 3.133e+00| constrast_loss: 3.056e+00| div_loss: 7.721e-01| %_mask_idx: 4.738e-01| ppl: 1.459e+02| lr: 1.800e-06| temp: 1.982e+00| grad_norm: 3.797e+00\n",
            "| completed_steps: 1.900e+03| loss: 3.239e+00| constrast_loss: 3.158e+00| div_loss: 8.158e-01| %_mask_idx: 4.887e-01| ppl: 1.179e+02| lr: 1.900e-06| temp: 1.981e+00| grad_norm: 4.291e+00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in /content/drive/MyDrive/checkpoints_10/checkpoint-2000/config.json\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| completed_steps: 2.000e+03| loss: 2.945e+00| constrast_loss: 2.864e+00| div_loss: 8.186e-01| %_mask_idx: 4.652e-01| ppl: 1.161e+02| lr: 2.000e-06| temp: 1.980e+00| grad_norm: 3.920e+00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in /content/drive/MyDrive/checkpoints_10/checkpoint-2000/pytorch_model.bin\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| completed_steps: 2.100e+03| loss: 2.985e+00| constrast_loss: 2.905e+00| div_loss: 7.939e-01| %_mask_idx: 4.947e-01| ppl: 1.319e+02| lr: 2.100e-06| temp: 1.979e+00| grad_norm: 5.399e+00\n",
            "| completed_steps: 2.200e+03| loss: 3.039e+00| constrast_loss: 2.963e+00| div_loss: 7.636e-01| %_mask_idx: 4.839e-01| ppl: 1.513e+02| lr: 2.200e-06| temp: 1.978e+00| grad_norm: 3.444e+00\n",
            "| completed_steps: 2.300e+03| loss: 3.202e+00| constrast_loss: 3.122e+00| div_loss: 8.012e-01| %_mask_idx: 5.019e-01| ppl: 1.272e+02| lr: 2.300e-06| temp: 1.977e+00| grad_norm: 5.167e+00\n",
            "| completed_steps: 2.400e+03| loss: 3.207e+00| constrast_loss: 3.125e+00| div_loss: 8.196e-01| %_mask_idx: 4.749e-01| ppl: 1.154e+02| lr: 2.400e-06| temp: 1.976e+00| grad_norm: 5.049e+00\n",
            "| completed_steps: 2.500e+03| loss: 3.022e+00| constrast_loss: 2.942e+00| div_loss: 8.027e-01| %_mask_idx: 4.865e-01| ppl: 1.263e+02| lr: 2.500e-06| temp: 1.975e+00| grad_norm: 3.107e+00\n",
            "| completed_steps: 2.600e+03| loss: 2.607e+00| constrast_loss: 2.531e+00| div_loss: 7.613e-01| %_mask_idx: 4.937e-01| ppl: 1.528e+02| lr: 2.600e-06| temp: 1.974e+00| grad_norm: 4.272e+00\n",
            "| completed_steps: 2.700e+03| loss: 3.410e+00| constrast_loss: 3.330e+00| div_loss: 7.984e-01| %_mask_idx: 4.689e-01| ppl: 1.290e+02| lr: 2.700e-06| temp: 1.973e+00| grad_norm: 3.586e+00\n",
            "| val_loss: 2.386e+00| val_contrastive_loss: 2.303e+00| val_diversity_loss: 8.279e-01| val_num_losses: 1.000e+00\n",
            "| completed_steps: 2.800e+03| loss: 2.848e+00| constrast_loss: 2.769e+00| div_loss: 7.901e-01| %_mask_idx: 4.969e-01| ppl: 1.343e+02| lr: 2.800e-06| temp: 1.972e+00| grad_norm: 3.251e+00\n",
            "| completed_steps: 2.900e+03| loss: 3.069e+00| constrast_loss: 2.984e+00| div_loss: 8.544e-01| %_mask_idx: 4.705e-01| ppl: 9.321e+01| lr: 2.900e-06| temp: 1.971e+00| grad_norm: 9.230e+00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in /content/drive/MyDrive/checkpoints_10/checkpoint-3000/config.json\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| completed_steps: 3.000e+03| loss: 2.575e+00| constrast_loss: 2.495e+00| div_loss: 7.999e-01| %_mask_idx: 5.015e-01| ppl: 1.280e+02| lr: 3.000e-06| temp: 1.970e+00| grad_norm: 4.743e+00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in /content/drive/MyDrive/checkpoints_10/checkpoint-3000/pytorch_model.bin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| completed_steps: 3.100e+03| loss: 2.864e+00| constrast_loss: 2.782e+00| div_loss: 8.183e-01| %_mask_idx: 4.575e-01| ppl: 1.163e+02| lr: 3.100e-06| temp: 1.969e+00| grad_norm: 4.266e+00\n",
            "| completed_steps: 3.200e+03| loss: 2.727e+00| constrast_loss: 2.649e+00| div_loss: 7.880e-01| %_mask_idx: 4.977e-01| ppl: 1.357e+02| lr: 3.200e-06| temp: 1.968e+00| grad_norm: 5.737e+00\n",
            "| completed_steps: 3.300e+03| loss: 2.536e+00| constrast_loss: 2.457e+00| div_loss: 7.833e-01| %_mask_idx: 4.929e-01| ppl: 1.387e+02| lr: 3.300e-06| temp: 1.967e+00| grad_norm: 4.406e+00\n",
            "| completed_steps: 3.400e+03| loss: 2.346e+00| constrast_loss: 2.264e+00| div_loss: 8.252e-01| %_mask_idx: 4.753e-01| ppl: 1.119e+02| lr: 3.400e-06| temp: 1.966e+00| grad_norm: 4.633e+00\n",
            "| completed_steps: 3.500e+03| loss: 2.798e+00| constrast_loss: 2.722e+00| div_loss: 7.602e-01| %_mask_idx: 4.830e-01| ppl: 1.535e+02| lr: 3.500e-06| temp: 1.965e+00| grad_norm: 4.021e+00\n",
            "| completed_steps: 3.600e+03| loss: 2.528e+00| constrast_loss: 2.448e+00| div_loss: 8.052e-01| %_mask_idx: 4.955e-01| ppl: 1.246e+02| lr: 3.600e-06| temp: 1.964e+00| grad_norm: 5.783e+00\n",
            "| completed_steps: 3.700e+03| loss: 2.616e+00| constrast_loss: 2.534e+00| div_loss: 8.289e-01| %_mask_idx: 5.050e-01| ppl: 1.095e+02| lr: 3.700e-06| temp: 1.963e+00| grad_norm: 3.969e+00\n",
            "| completed_steps: 3.800e+03| loss: 3.105e+00| constrast_loss: 3.028e+00| div_loss: 7.729e-01| %_mask_idx: 5.020e-01| ppl: 1.454e+02| lr: 3.800e-06| temp: 1.962e+00| grad_norm: 4.246e+00\n",
            "| completed_steps: 3.900e+03| loss: 2.626e+00| constrast_loss: 2.547e+00| div_loss: 7.933e-01| %_mask_idx: 4.827e-01| ppl: 1.323e+02| lr: 3.900e-06| temp: 1.961e+00| grad_norm: 3.630e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Configuration saved in /content/drive/MyDrive/checkpoints_10/checkpoint-4000/config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| completed_steps: 4.000e+03| loss: 2.584e+00| constrast_loss: 2.503e+00| div_loss: 8.038e-01| %_mask_idx: 5.071e-01| ppl: 1.256e+02| lr: 4.000e-06| temp: 1.960e+00| grad_norm: 4.441e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model weights saved in /content/drive/MyDrive/checkpoints_10/checkpoint-4000/pytorch_model.bin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| completed_steps: 4.100e+03| loss: 2.779e+00| constrast_loss: 2.695e+00| div_loss: 8.365e-01| %_mask_idx: 4.545e-01| ppl: 1.046e+02| lr: 4.100e-06| temp: 1.959e+00| grad_norm: 6.922e+00\n",
            "| val_loss: 2.372e+00| val_contrastive_loss: 2.288e+00| val_diversity_loss: 8.308e-01| val_num_losses: 1.000e+00\n",
            "| completed_steps: 4.200e+03| loss: 3.227e+00| constrast_loss: 3.140e+00| div_loss: 8.737e-01| %_mask_idx: 5.122e-01| ppl: 8.080e+01| lr: 4.200e-06| temp: 1.958e+00| grad_norm: 6.237e+00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 16>\u001b[0m:\u001b[94m33\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/accelerate/\u001b[0m\u001b[1;33maccelerator.py\u001b[0m:\u001b[94m1316\u001b[0m in \u001b[92mbackward\u001b[0m               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1313 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m \u001b[96mself\u001b[0m.scaler \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1314 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.scaler.scale(loss).backward(**kwargs)                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1315 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1316 \u001b[2m│   │   │   \u001b[0mloss.backward(**kwargs)                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1317 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1318 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92munscale_gradients\u001b[0m(\u001b[96mself\u001b[0m, optimizer=\u001b[94mNone\u001b[0m):                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1319 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/\u001b[0m\u001b[1;33m_tensor.py\u001b[0m:\u001b[94m487\u001b[0m in \u001b[92mbackward\u001b[0m                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 484 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mcreate_graph=create_graph,                                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 485 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minputs=inputs,                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 486 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 487 \u001b[2m│   │   \u001b[0mtorch.autograd.backward(                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 488 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m, gradient, retain_graph, create_graph, inputs=inputs                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 489 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 490 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/autograd/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m197\u001b[0m in \u001b[92mbackward\u001b[0m               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m194 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# The reason we repeat same the comment below is that\u001b[0m                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m195 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# some Python versions print out the first line of a multi-line function\u001b[0m               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m196 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# calls in the traceback and some print out the last line\u001b[0m                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m197 \u001b[2m│   \u001b[0mVariable._execution_engine.run_backward(  \u001b[2m# Calls into the C++ engine to run the bac\u001b[0m   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m198 \u001b[0m\u001b[2m│   │   \u001b[0mtensors, grad_tensors_, retain_graph, create_graph, inputs,                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m199 \u001b[0m\u001b[2m│   │   \u001b[0mallow_unreachable=\u001b[94mTrue\u001b[0m, accumulate_grad=\u001b[94mTrue\u001b[0m)  \u001b[2m# Calls into the C++ engine to ru\u001b[0m   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m200 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 16&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">33</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/accelerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">accelerator.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1316</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1313 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scaler <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1314 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scaler.scale(loss).backward(**kwargs)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1315 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1316 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>loss.backward(**kwargs)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1317 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1318 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">unscale_gradients</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, optimizer=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>):                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1319 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_tensor.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">487</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 484 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>create_graph=create_graph,                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 485 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>inputs=inputs,                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 486 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 487 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>torch.autograd.backward(                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 488 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, gradient, retain_graph, create_graph, inputs=inputs                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 489 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 490 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/autograd/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init__.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">197</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">194 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># The reason we repeat same the comment below is that</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">195 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># some Python versions print out the first line of a multi-line function</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">196 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># calls in the traceback and some print out the last line</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>197 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>Variable._execution_engine.run_backward(  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to run the bac</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">198 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>tensors, grad_tensors_, retain_graph, create_graph, inputs,                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">199 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>allow_unreachable=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>, accumulate_grad=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to ru</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">200 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 5. Train\n",
        "total_batch_size = args.per_device_train_batch_size * accelerator.num_processes * args.gradient_accumulation_steps\n",
        "\n",
        "logger.info(\"***** Running training *****\")\n",
        "logger.info(f\"  Num examples = {len(vectorized_datasets['train'])}\")\n",
        "logger.info(f\"  Num Epochs = {args.num_train_epochs}\")\n",
        "logger.info(f\"  Instantaneous batch size per device = {args.per_device_train_batch_size}\")\n",
        "logger.info(f\"  Total train batch size (w. parallel, distributed & accumulation) = {total_batch_size}\")\n",
        "logger.info(f\"  Gradient Accumulation steps = {args.gradient_accumulation_steps}\")\n",
        "logger.info(f\"  Total optimization steps = {args.max_train_steps}\")\n",
        "completed_steps = 0\n",
        "\n",
        "# Only show the progress bar once on each machine.\n",
        "progress_bar = tqdm(range(args.max_train_steps), disable=not accelerator.is_local_main_process)\n",
        "completed_steps = 0\n",
        "for epoch in range(args.num_train_epochs):\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # compute num of losses\n",
        "        num_losses = batch[\"mask_time_indices\"].sum()\n",
        "        sub_attention_mask = batch.pop(\"sub_attention_mask\", None)\n",
        "        sub_attention_mask = (\n",
        "            sub_attention_mask if sub_attention_mask is not None else torch.ones_like(batch[\"mask_time_indices\"])\n",
        "        )\n",
        "        percent_masked = num_losses / sub_attention_mask.sum()\n",
        "\n",
        "        # forward\n",
        "        outputs = model(**batch)\n",
        "\n",
        "        # divide loss by gradient accumulation steps since gradients\n",
        "        # are accumulated for multiple backward passes in PyTorch\n",
        "        loss = outputs.loss / args.gradient_accumulation_steps\n",
        "        accelerator.backward(loss)\n",
        "\n",
        "        # make sure that `num_losses` is summed for distributed training\n",
        "        # and average gradients over losses of all devices\n",
        "        if accelerator.state.num_processes > 1:\n",
        "            num_losses = accelerator.gather(num_losses).sum()\n",
        "            gradient_multiplier = accelerator.state.num_processes / num_losses\n",
        "            multiply_grads(model.module.parameters(), gradient_multiplier)\n",
        "        else:\n",
        "            multiply_grads(model.parameters(), 1 / num_losses)\n",
        "\n",
        "        # update step\n",
        "        if (step + 1) % args.gradient_accumulation_steps == 0 or step == len(train_dataloader) - 1:\n",
        "\n",
        "            # compute grad norm for monitoring\n",
        "            scale = (\n",
        "                accelerator.scaler._scale.item()\n",
        "                if hasattr(accelerator, \"scaler\") and accelerator.scaler is not None\n",
        "                else 1\n",
        "            )\n",
        "            if accelerator.state.num_processes > 1:\n",
        "                grad_norm = get_grad_norm(model.module.parameters(), scale)\n",
        "            else:\n",
        "                grad_norm = get_grad_norm(model.parameters(), scale)\n",
        "\n",
        "            # update parameters\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if not accelerator.optimizer_step_was_skipped:\n",
        "                lr_scheduler.step()\n",
        "            elif accelerator.is_local_main_process:\n",
        "                progress_bar.write(\n",
        "                    \"Gradients have overflown - skipping update step... \" f\"Updating gradient scale to {scale}...\"\n",
        "                )\n",
        "\n",
        "            # update gumbel temperature\n",
        "            gumbel_temperature = max(\n",
        "                args.max_gumbel_temperature * args.gumbel_temperature_decay**completed_steps,\n",
        "                args.min_gumbel_temperature,\n",
        "            )\n",
        "            if hasattr(model, \"module\"):\n",
        "                model.module.set_gumbel_temperature(gumbel_temperature)\n",
        "            else:\n",
        "                model.set_gumbel_temperature(gumbel_temperature)\n",
        "\n",
        "            progress_bar.update(1)\n",
        "            completed_steps += 1\n",
        "\n",
        "        # 6. Log all results\n",
        "        if completed_steps % args.logging_steps == 0 \\\n",
        "                and (step + 1) % args.gradient_accumulation_steps == 0:\n",
        "            loss.detach()\n",
        "            outputs.contrastive_loss.detach()\n",
        "            outputs.diversity_loss.detach()\n",
        "\n",
        "            if accelerator.state.num_processes > 1:\n",
        "                loss = accelerator.gather(loss).sum()\n",
        "                outputs.contrastive_loss = accelerator.gather(outputs.contrastive_loss).sum()\n",
        "                outputs.diversity_loss = accelerator.gather(outputs.diversity_loss).sum()\n",
        "                percent_masked = accelerator.gather(percent_masked).sum()\n",
        "\n",
        "            train_logs = {\n",
        "                \"completed_steps\": torch.tensor(completed_steps),\n",
        "                \"loss\": (loss * args.gradient_accumulation_steps) / num_losses,\n",
        "                \"constrast_loss\": outputs.contrastive_loss / num_losses,\n",
        "                \"div_loss\": outputs.diversity_loss / num_losses,\n",
        "                \"%_mask_idx\": percent_masked / accelerator.num_processes,\n",
        "                \"ppl\": outputs.codevector_perplexity,\n",
        "                \"lr\": torch.tensor(optimizer.param_groups[0][\"lr\"]),\n",
        "                \"temp\": torch.tensor(gumbel_temperature),\n",
        "                \"grad_norm\": torch.tensor(grad_norm),\n",
        "            }\n",
        "            log_str = \"\"\n",
        "            for k, v in train_logs.items():\n",
        "                log_str += \"| {}: {:.3e}\".format(k, v.item())\n",
        "\n",
        "            if accelerator.is_local_main_process:\n",
        "                progress_bar.write(log_str)\n",
        "                if is_wandb_available():\n",
        "                  wandb.log(train_logs)\n",
        "\n",
        "        # save model every `args.saving_steps` steps\n",
        "        ckpt_prefix = 'checkpoint-'\n",
        "        if completed_steps % args.saving_steps == 0 \\\n",
        "                and (step + 1) % args.gradient_accumulation_steps == 0:\n",
        "            if (args.push_to_hub and epoch < args.num_train_epochs - 1) or args.output_dir is not None:\n",
        "                accelerator.wait_for_everyone()\n",
        "                unwrapped_model = accelerator.unwrap_model(model)\n",
        "                #os.makedirs(os.path.join(args.output_dir, ckpt_prefix+str(step + 1)), exist_ok=True)\n",
        "                unwrapped_model.save_pretrained(os.path.join(args.output_dir, ckpt_prefix+str(completed_steps)),\n",
        "                                                save_function=accelerator.save)\n",
        "\n",
        "            if (args.push_to_hub and epoch < args.num_train_epochs - 1) and accelerator.is_main_process:\n",
        "                repo.push_to_hub(\n",
        "                    commit_message=f\"Training in progress step {completed_steps}\",\n",
        "                    blocking=False,\n",
        "                    auto_lfs_prune=True,\n",
        "                )\n",
        "\n",
        "        # if completed steps > `args.max_train_steps` stop\n",
        "        if completed_steps >= args.max_train_steps:\n",
        "            break\n",
        "\n",
        "    # 7. Validate!\n",
        "    model.eval()\n",
        "\n",
        "    # init logs\n",
        "    val_logs = {\n",
        "        \"val_loss\": 0,\n",
        "        \"val_contrastive_loss\": 0,\n",
        "        \"val_diversity_loss\": 0,\n",
        "        \"val_num_losses\": 0,\n",
        "    }\n",
        "    for step, batch in enumerate(eval_dataloader):\n",
        "        with torch.no_grad():\n",
        "            batch.pop(\"sub_attention_mask\", None)\n",
        "            outputs = model(**batch)\n",
        "\n",
        "        val_logs[\"val_loss\"] += outputs.loss\n",
        "        val_logs[\"val_contrastive_loss\"] += outputs.contrastive_loss\n",
        "        val_logs[\"val_diversity_loss\"] += outputs.diversity_loss\n",
        "        val_logs[\"val_num_losses\"] += batch[\"mask_time_indices\"].sum()\n",
        "\n",
        "    # sum over devices in multi-processing\n",
        "    if accelerator.num_processes > 1:\n",
        "        val_logs = {k: accelerator.gather(v).sum() for k, v in val_logs.items()}\n",
        "\n",
        "    val_logs = {k: v / val_logs[\"val_num_losses\"] for k, v in val_logs.items()}\n",
        "\n",
        "    log_str = \"\"\n",
        "    for k, v in val_logs.items():\n",
        "        log_str += \"| {}: {:.3e}\".format(k, v.item())\n",
        "\n",
        "    if accelerator.is_local_main_process:\n",
        "        progress_bar.write(log_str)\n",
        "        if is_wandb_available():\n",
        "            wandb.log(val_logs)\n",
        "\n",
        "    '''\n",
        "    if args.output_dir is not None:\n",
        "        accelerator.wait_for_everyone()\n",
        "        unwrapped_model = accelerator.unwrap_model(model)\n",
        "        unwrapped_model.save_pretrained(args.output_dir, save_function=accelerator.save)\n",
        "        if accelerator.is_main_process:\n",
        "            if args.push_to_hub:\n",
        "                repo.push_to_hub(commit_message=\"End of training\", auto_lfs_prune=True)\n",
        "    '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0aQrlyxHA5q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 4794816,
          "sourceId": 8115772,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30674,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bf7f58151ac647cc80cda03a63f2b81b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a82245e48ec9409fa16a5592dfec94b7",
              "IPY_MODEL_1c033c9c66234856aaebb798ea6068fb",
              "IPY_MODEL_ce751320f3a44e898144fa6748dd9da8"
            ],
            "layout": "IPY_MODEL_eb53e80df29746ef9d5aef75b7f21f37"
          }
        },
        "a82245e48ec9409fa16a5592dfec94b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdb2eab7c1f14825a56a27947bcda78f",
            "placeholder": "​",
            "style": "IPY_MODEL_3207a938bbff4176be594c91a894e66b",
            "value": "Resolving data files: 100%"
          }
        },
        "1c033c9c66234856aaebb798ea6068fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d08c2ecf5ffa4ab08515d673d5703e4a",
            "max": 3099,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a5e7bdd82a547deb5bfff3b67898e8a",
            "value": 3099
          }
        },
        "ce751320f3a44e898144fa6748dd9da8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4de83ae4782433395f708825f6d4554",
            "placeholder": "​",
            "style": "IPY_MODEL_66657332642e4b2b840e2f11ebefb4ce",
            "value": " 3099/3099 [00:00&lt;00:00, 22166.25it/s]"
          }
        },
        "eb53e80df29746ef9d5aef75b7f21f37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdb2eab7c1f14825a56a27947bcda78f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3207a938bbff4176be594c91a894e66b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d08c2ecf5ffa4ab08515d673d5703e4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a5e7bdd82a547deb5bfff3b67898e8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b4de83ae4782433395f708825f6d4554": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66657332642e4b2b840e2f11ebefb4ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e250fd1cf494807ab5472b9d5d31537": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8ec8c75b5c0492e9ccf25255affcbca",
              "IPY_MODEL_e8a1dd58d3f04c6f8f73f259ffa3eaaa",
              "IPY_MODEL_ec5cf077253f4ce38db5f4859ec4ded0"
            ],
            "layout": "IPY_MODEL_48a1f60d2aa14ce2890b87afa1ed9382"
          }
        },
        "e8ec8c75b5c0492e9ccf25255affcbca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87f0ba8d91714d2fbc57089a82cf4e12",
            "placeholder": "​",
            "style": "IPY_MODEL_2d278f7b50dd4ef9ba8ea28a5df99eae",
            "value": "Generating train split: "
          }
        },
        "e8a1dd58d3f04c6f8f73f259ffa3eaaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cda0e8a22014ec6ac8eb32ad2e3f1ae",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ddc76efd5e84c65940f14d1d6e56c5f",
            "value": 1
          }
        },
        "ec5cf077253f4ce38db5f4859ec4ded0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de815217b00e4fcc86c55b8c28d19ab4",
            "placeholder": "​",
            "style": "IPY_MODEL_1ea777a415f0424c810f7b06ba1f4e93",
            "value": " 3099/0 [00:00&lt;00:00, 17713.29 examples/s]"
          }
        },
        "48a1f60d2aa14ce2890b87afa1ed9382": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87f0ba8d91714d2fbc57089a82cf4e12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d278f7b50dd4ef9ba8ea28a5df99eae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cda0e8a22014ec6ac8eb32ad2e3f1ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "0ddc76efd5e84c65940f14d1d6e56c5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de815217b00e4fcc86c55b8c28d19ab4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ea777a415f0424c810f7b06ba1f4e93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f4e7cd9c57a4a058fa00f884320c299": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df671a6383484181b5b2bef16bc9a17d",
              "IPY_MODEL_a3d6772b7a4549d1a50368484a36af27",
              "IPY_MODEL_71b9d4af78d94f6db1929c583573cfb9"
            ],
            "layout": "IPY_MODEL_2b64aa135fe3492a9997122d10a361f3"
          }
        },
        "df671a6383484181b5b2bef16bc9a17d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38cacdf87e7c4294bbb4d92411f76189",
            "placeholder": "​",
            "style": "IPY_MODEL_c2f1bfe54bf34900a2f3413eeaf55e2d",
            "value": "  9%"
          }
        },
        "a3d6772b7a4549d1a50368484a36af27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fbbe848d0cd42d2ba78890fcb6fcd95",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d44c205527864f3d876f3a243bdd68ce",
            "value": 4293
          }
        },
        "71b9d4af78d94f6db1929c583573cfb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59d47e40581a488bac5af0aafce183a3",
            "placeholder": "​",
            "style": "IPY_MODEL_ecb9f62ca56a40a88fd350909a799b54",
            "value": " 4293/50000 [2:48:42&lt;23:40:30,  1.86s/it]"
          }
        },
        "2b64aa135fe3492a9997122d10a361f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38cacdf87e7c4294bbb4d92411f76189": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2f1bfe54bf34900a2f3413eeaf55e2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fbbe848d0cd42d2ba78890fcb6fcd95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d44c205527864f3d876f3a243bdd68ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59d47e40581a488bac5af0aafce183a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecb9f62ca56a40a88fd350909a799b54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}