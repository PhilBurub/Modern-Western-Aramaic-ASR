{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install speechbrain"
      ],
      "metadata": {
        "id": "avaqqXR8yZ46"
      },
      "id": "avaqqXR8yZ46",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d02b5b2",
      "metadata": {
        "id": "9d02b5b2"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy\n",
        "import pandas\n",
        "import librosa\n",
        "import soundfile\n",
        "from speechbrain.pretrained import VAD\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fb3fa83",
      "metadata": {
        "id": "5fb3fa83"
      },
      "outputs": [],
      "source": [
        "def detect_voice(\n",
        "    path,\n",
        "    activation_threshold = 0.70,\n",
        "    deactivation_threshold = 0.25,\n",
        "    min_pause = 0.200,\n",
        "    min_activation = 0.100,\n",
        "    save_dir = 'model_dir',\n",
        "    segment_pre = 0.0,\n",
        "    segment_post = 0.0,\n",
        "    double_check_threshold = None,\n",
        "    parallel_chunks = 4,\n",
        "    chunk_size = 1.0,\n",
        "    overlap_chunks = True,\n",
        "    ):\n",
        "\n",
        "    # do initial, coarse-detection\n",
        "    vad = VAD.from_hparams(source=\"speechbrain/vad-crdnn-libriparty\", savedir=save_dir)\n",
        "\n",
        "    probabilities = vad.get_speech_prob_file(path,\n",
        "        large_chunk_size=chunk_size*parallel_chunks,\n",
        "        small_chunk_size=chunk_size,\n",
        "        overlap_small_chunk=overlap_chunks)\n",
        "\n",
        "    thresholded = vad.apply_threshold(probabilities,\n",
        "        activation_th=activation_threshold,\n",
        "        deactivation_th=deactivation_threshold).float()\n",
        "\n",
        "    boundaries = vad.get_boundaries(thresholded)\n",
        "\n",
        "    # refine boundaries using energy-based VAD\n",
        "    boundaries = vad.energy_VAD(path, boundaries,\n",
        "            activation_th=activation_threshold,\n",
        "            deactivation_th=deactivation_threshold)\n",
        "\n",
        "    # post-process to clean up\n",
        "    if min_pause is not None:\n",
        "        boundaries = vad.merge_close_segments(boundaries, close_th=min_pause)\n",
        "\n",
        "    if min_activation is not None:\n",
        "        boundaries = vad.remove_short_segments(boundaries, len_th=min_activation)\n",
        "\n",
        "    if double_check_threshold:\n",
        "        boundaries = vad.double_check_speech_segments(boundaries, speech_th=double_check_threshold)\n",
        "\n",
        "    # convert to friendly pandas DataFrames with time info\n",
        "    events = pandas.DataFrame(boundaries, columns=['start', 'end'])\n",
        "    events['class'] = 'speech'\n",
        "\n",
        "    p = numpy.squeeze(probabilities)\n",
        "    times = pandas.Series(numpy.arange(0, len(p)) * vad.time_resolution, name='time')\n",
        "    p = pandas.DataFrame(p, columns=['speech'], index=times)\n",
        "\n",
        "    return p, events"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ace92be6",
      "metadata": {
        "id": "ace92be6"
      },
      "outputs": [],
      "source": [
        "vad = VAD.from_hparams(source=\"speechbrain/vad-crdnn-libriparty\", savedir='model_dir')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3d9b54b",
      "metadata": {
        "id": "b3d9b54b"
      },
      "outputs": [],
      "source": [
        "def load_split_audio(audio_path: Path, dest_path: Path):\n",
        "    audio, sr = librosa.load(str(audio_path), sr=None)\n",
        "    resampled = librosa.resample(audio, orig_sr=sr, target_sr=16000)\n",
        "\n",
        "    cache_folder = Path('./cache/')\n",
        "    if not cache_folder.exists():\n",
        "        cache_folder.mkdir()\n",
        "    if not dest_path.exists():\n",
        "        dest_path.mkdir()\n",
        "\n",
        "    cache_file = Path('./cache/').joinpath(audio_path.name)\n",
        "    soundfile.write(str(cache_file), data=resampled, samplerate=16000)\n",
        "\n",
        "    stem = audio_path.stem\n",
        "    dest_audio = dest_path.joinpath(audio_path.name)\n",
        "    timestamps = detect_voice(str(cache_file), min_pause=2, min_activation=2)\n",
        "    path = Path('./resample&split/')\n",
        "    for row in timestamps[1].itertuples():\n",
        "        name = dest_audio.with_stem(f'{stem}_{row.Index}')\n",
        "        start, end = round(row.start*16000), round(row.end*16000)\n",
        "        soundfile.write(str(name), data=resampled[start:end], samplerate=16000)\n",
        "    cache_file.unlink()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0810da06-c6f0-409e-997a-d7957d27eec5",
      "metadata": {
        "id": "0810da06-c6f0-409e-997a-d7957d27eec5"
      },
      "outputs": [],
      "source": [
        "total_data = list(Path('./data/audio').iterdir()) + list(Path('./data/text+audio/audio').iterdir())\n",
        "output_path = Path('./resample_split/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc7ffaec",
      "metadata": {
        "id": "fc7ffaec",
        "outputId": "65cbdb4e-71d2-4c7e-80c4-e302e2541864"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████████████████████████████████████████████| 193/193 [19:02<00:00,  5.92s/it]\n"
          ]
        }
      ],
      "source": [
        "for filepath in tqdm(total_data):\n",
        "    load_split_audio(filepath, output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec0b0a1d-13af-493c-80e8-952348990c68",
      "metadata": {
        "id": "ec0b0a1d-13af-493c-80e8-952348990c68"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import librosa\n",
        "from tqdm import tqdm\n",
        "\n",
        "def resample(audio_path: Path):\n",
        "  for filepath in tqdm(list(audio_path.iterdir())):\n",
        "    audio, sr = librosa.load(str(filepath), sr=None)\n",
        "    if sr != 16000:\n",
        "      resampled = librosa.resample(audio, orig_sr=sr, target_sr=16000)\n",
        "      soundfile.write(str(filepath), data=resampled, samplerate=16000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resample(Path('/content/drive/MyDrive/dataset/audio'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_NBVC-XSK_j",
        "outputId": "61c2fd00-23b4-4dee-f410-ad84cedb49e4"
      },
      "id": "I_NBVC-XSK_j",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19794/19794 [05:46<00:00, 57.18it/s] \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}